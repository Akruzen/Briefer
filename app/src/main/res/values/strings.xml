<resources>
    <string name="app_name">Briefer</string>
    <string name="about_app">A demo application based on TensorFlow\'s BERT to perform NLP operations on runtime contents.
    This app runs completely offline.\n\n\nDesigned and Developed by:\nOmkar Phadke</string>
    <string name="lorem_ipsum">
        Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut dictum vulputate diam, non mattis nunc tristique eu.
        Aliquam nisl ex, condimentum non consectetur vitae, sodales sit amet massa. Pellentesque efficitur leo ut neque
        iaculis blandit a ac velit. Donec commodo vel mi quis posuere. Maecenas in felis vitae nibh laoreet pulvinar non ac
        velit. Sed feugiat ut sem in pulvinar. Vestibulum mattis euismod felis, in gravida leo. Phasellus cursus risus a augue
        gravida molestie. Mauris congue et urna vitae eleifend. Aliquam magna massa, placerat eu felis vel, feugiat semper metus.
        Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Aenean egestas justo ante.
        Nunc at augue vitae nibh malesuada finibus vel quis turpis. Morbi a facilisis nisi. Suspendisse porttitor elit sit amet
        velit rutrum, interdum semper dolor placerat. Maecenas eget lacus lectus. In at massa volutpat, faucibus dui sed, imperdiet
        libero. Aenean sed metus vitae diam tempor imperdiet non sed purus. Nullam at neque pellentesque, placerat mi in, eleifend
        nulla. Pellentesque mollis ligula at aliquet vulputate.
    </string>
    <string name="about_bert">
        Google released mobileBERT (Bidirectional Encoder Representations from Transformers) in 2018 aiming for high performance
        lightweight Natural Language Processing for processors having limited resources such as those of smartphones. It is based
        on Tensorflow Lite model which can be used to build a system that can answer users\' questions in natural language. In 2022,
        Google launched an non-compiled proof-of-concept application on GitHub for showcasing BERT\'s usage on Android smartphones.
        This app uses the same BERT technology under the hood.
    </string>
    <string name="how_to_use">
        Tap the \"+\" button on home screen of the app to add a topic. Then, enter a suitable title for your text and paste/type in
        your text content. Tap Save icon. The title of your text will appear in the home screen list. Tap the list item. You can now
        ask questions based on the text content you had inserted.
    </string>
    <string name="points_to_consider">
        Take a note of the following points while you ask questions:\n\n
        1. The model cannot generate text on its own. Hence, the results will always be a part of the text you have provided.\n
        2. Since text generation is not possible, questions like \"Summarize the paragraph\", \"Predict the outcome\" or any such
        similar queries may produce garbage results.\n
        3. From a list of results, top 5 results are shown, where first is most likely and 5th is least likely.\n
        4. Try phrasing your questions in such a way, that they end in a question mark and start with a \"Wh\" type word.
        For example, instead of asking \"Do you know the CEO of Google?\" or \"Tell me the name of CEO of Google.\", ask
        \"Who is the CEO of Google?\"
    </string>
    <string name="threads_info">
        Threads are used to improve performance by allowing multiple operations to run simultaneously.
        Increasing number of threads increases computing speed but also increases the load on the delegate.\n
        A Delegate is a software component that can be used to accelerate the execution of TensorFlow Lite models.
        Delegates can be used to leverage on-device accelerators such as the GPU (Graphics Processing Unit), CPU (Central Processing
        Unit), and NNAPI (Android Neural Networks API).
    </string>
    <string name="threads_warning">Warning: These settings usually don\'t require alterations. Only proceed if you know what you are doing.</string>
</resources>